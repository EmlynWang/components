{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PCB Defect Detection using Yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows you how to use the `dlpy.mzmodel` subpackage to create a Yolov5 model to perform defect detection. The `dlpy.mzmodel` subpackage leverages the [SAS Deep Learning Model Zoo](https://go.documentation.sas.com/doc/en/pgmsascdc/latest/casdlmzpg/titlepage.htm) utilities to manage deep learning models on the CAS server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Set Up Environment](#setup)\n",
    "2. [Load and Visualize Printed Circuit Board Defect Images](#prepare)\n",
    "3. [Build the Model](#build)\n",
    "4. [Train the Model](#train)\n",
    "5. [Score the Model and Visualize Scoring Results](#score)\n",
    "5. [Register Model to Model Repository](#register)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set Up Environment <a id=\"setup\"><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the various Python and SAS DLPy packages that will be used in this notebook session. Begin by importing the SAS Scripting Wrapper for Analytics Transfer (SWAT). SWAT is the Python interface to SAS CAS. Here is more information about [starting a SAS CAS session with the SWAT package](https://sassoftware.github.io/python-swat/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SASCTL, SAS-DLPy, and SAS SWAT are all different SAS software packages used for data analysis, modeling and deep learning.\n",
    "\n",
    "- SASCTL is a Python package that provides a high-level interface to SAS Viya REST APIs for managing and monitoring SAS Viya environments.\n",
    "\n",
    "- SAS-DLPy is a Python package that provides a high-level interface to SAS Viya Deep Learning APIs for building and training deep learning models.\n",
    "\n",
    "- SAS SWAT (SAS Scripting Wrapper for Analytics Transfer) is a Python package that provides a low-level interface to SAS Viya APIs for data preparation, exploration, and modeling.\n",
    "\n",
    "All of these packages are designed to work with SAS Viya, a cloud-native and in-memory analytics platform that provides distributed computing, machine learning and deep learning capabilities. SAS Viya enables organizations to process large amounts of data, build and deploy models at scale, and integrate with other systems and languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import getpass\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import swat as sw\n",
    "import sasctl\n",
    "sys.path.append('python-dlpy')\n",
    "import dlpy\n",
    "from dlpy.utils import *\n",
    "from dlpy.mzmodel import *\n",
    "from dlpy.splitting import *\n",
    "\n",
    "os.environ[\"CAS_CLIENT_SSL_CA_LIST\"] = \"https.crt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I am using DLPY\", dlpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = \"<your username>\"\n",
    "password = getpass.getpass(\"Enter Password: \")\n",
    "\n",
    "# Create a CAS session instance and provide connection information to your running CAS server.\n",
    "s = sw.CAS('https://gtptest.apdemo.sas.com/cas-shared-gputmp-http', username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Visualize Printed Circuit Board Defect Images <a id=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is available at https://github.com/Ixiaohuihuihui/Tiny-Defect-Detection-for-PCB (Forked from: Feature Pyramid Networks for Object Detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Visualize the 6 different defect classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads sample images\n",
    "s.loadTable(path=\"samples.sashdat\", caslib=\"public\", casout={\"name\":\"samples\", \"caslib\":\"casuser\", \"replace\":True})\n",
    "\n",
    "\n",
    "# Display and visualize the images in \"samples\" image table\n",
    "display_object_detections(s, \n",
    "                          'samples', \n",
    "                          'yolo', \n",
    "                          max_objects=5, \n",
    "                          num_plot=6, \n",
    "                          n_col=2\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Load images for Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load the image table (around 200 over images) into memory to start the model building process.\n",
    "\n",
    "s.loadTable(path=\"workshop_images.sashdat\", caslib=\"public\", casout={\"name\":\"workshop_images\", \"caslib\":\"casuser\", \"replace\":True})\n",
    "\n",
    "workshop_images = s.CASTable(name=\"workshop_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Examine Summary Statistics of the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the images into our training and tesing set\n",
    "\n",
    "column_list = workshop_images.columns.to_list()\n",
    "column_list.remove(\"_image_\")\n",
    "column_list.remove(\"_id_\")\n",
    "\n",
    "train_set, test_set = two_way_split(workshop_images,\n",
    "                                   test_rate=20,\n",
    "                                   stratify_by='_Object0_',\n",
    "                                   train_name='pcb_train',\n",
    "                                   test_name='pcb_test',\n",
    "                                   columns=column_list\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To view a table in-memory, we can run a \"fetch\" function.\n",
    "\n",
    "train_set.fetch(to=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To inspect and verify the metadata summary for the images in train_set, you can run \"image_summary\" from \"trainSetTbl\". \n",
    "# It is important to make sure the image size is 640 x 640.\n",
    "\n",
    "trainSetTbl = ImageTable.from_table(train_set)\n",
    "trainSetTbl.image_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Examine Object Class Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After using an imageTable to verify the subsetted training data image contents, \n",
    "# we can examine the distribution the object image classes CAS train/test table.\n",
    "\n",
    "# Object class distribution for \"train_set\".\n",
    "\n",
    "s.simple.freq(table={'name':train_set,'vars':[{'name':'_Object0_'}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object class distribution for \"test_set\".\n",
    "\n",
    "s.simple.freq(table={'name':test_set,'vars':[{'name':'_Object0_'}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the model <a id=\"build\"><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv5 is a real-time object detection algorithm that is an evolution of the popular YOLO (You Only Look Once) series of algorithms. The algorithm was developed by Ultralytics and was released in June 2020. YOLOv5 is a deep learning model that uses convolutional neural networks (CNNs) to detect and classify objects in real-time.\n",
    "\n",
    "Overall, YOLOv5 is an accurate and efficient object detection algorithm that is suitable for a wide range of applications. Its combination of accuracy, speed, and versatility make it an attractive option for developers and researchers working on object detection problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be building the Yolov5 model, here's how the architecture looks like.\n",
    "\n",
    "display(Image(filename='YOLOv5-1 Network Architecture.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture Source: [article](https://iq.opengenus.org/yolov5/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Get Anchor Boxes from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most utilized anchor box dimensions in the training data trainset and save the resulting anchor box values. Anchor box values are a list of scalar value pairs that represent the normalized box sizes in width and height for objects to be detected. The normalized box sizes are scalar quantities because they are calculated by dividing the box size (pixels) by the grid size (pixels).\n",
    "\n",
    "In order, items in an anchor box list represent:\n",
    "\n",
    "- AnchorBox1_width,\n",
    "- AnchorBox1_height,\n",
    "- AnchorBox2_width,\n",
    "- AnchorBox2_height,\n",
    "- ...\n",
    "- AnchorBoxN_width,\n",
    "- AnchorBoxN_height\n",
    "\n",
    "With `n_anchors=9`, there should be nine anchor box value pairs.\n",
    "\n",
    "Use the SAS DLPy  `get_anchors()` function to retrieve an array that specifies the best `n_anchors` value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_boxes = get_anchors(s, train_set, 'yolo', image_size=640, n_anchors=9)\n",
    "anchors = ' '.join(map(str, anchor_boxes))\n",
    "\n",
    "#anchors = '10 13 16 30 33 23 30 61 62 45 59 119 116 90 156 198 373 326' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output returns nine anchor box value pairs. It is easier to visualize the anchor box shapes by grouping the output into 9 `width x height` coordinate pairs. \n",
    "\n",
    "As follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair up elements of the tuple\n",
    "pairs = []\n",
    "for i in range(0, len(anchor_boxes), 2):\n",
    "    pairs.append((anchor_boxes[i], anchor_boxes[i+1]))\n",
    "\n",
    "# Print the pairs\n",
    "print(\"Coordinate pairs:\",pairs)\n",
    "\n",
    "# Get smallest and largest tuples in terms of difference between elements\n",
    "smallest_tuple = min(pairs, key=lambda x: abs(x[0] - x[1]))\n",
    "largest_tuple = max(pairs, key=lambda x: abs(x[0] - x[1]))\n",
    "\n",
    "# Print the results\n",
    "print(\"\\n\")\n",
    "print(\"Smallest tuple:\", smallest_tuple)\n",
    "print(\"Largest tuple:\", largest_tuple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show a range of normalized scalar anchor box sizes and shapes and shows the smallest and largest `width x height` coordinate pairs. \n",
    "\n",
    "These anchor box value pairs saved to the python variable `anchors` will be used in the upcoming model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Define the Object Detection YOLOv5 Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use SAS DLPy to define the YOLOv5 model architecture. The table `anchor_boxes` contains the anchor shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MZModel(conn=s, \n",
    "                model_name = \"YoloV5\",\n",
    "                model_type = \"TorchNative\", \n",
    "                dataset_type= \"OBJDETECT\", \n",
    "                anchors = anchors,\n",
    "                num_classes=6,\n",
    "                caslib=\"casuser\",\n",
    "                model_path=\"/shared-data/pcb_defects/models/traced_yolov5s.pt\",\n",
    "                model_subtype = \"SMALL\"                \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model <a id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `train()` method of the `MZModel` class to train the model. Use `inputs` to specify the column that contains the raw images and `targets` to specify the column that contains the annotation images. Pass your optimizer and gpu settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define your hyperparameters tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Optimizer(seed=12345, \n",
    "                    algorithm=SGDSolver(lr=0.001),\n",
    "                    batch_size=10,\n",
    "                    max_epochs=10                   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define your targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_det_targets = ['_nObjects_',\n",
    " '_Object0_',\n",
    " '_Object0_x',\n",
    " '_Object0_y',\n",
    " '_Object0_width',\n",
    " '_Object0_height',\n",
    " '_Object1_',\n",
    " '_Object1_x',\n",
    " '_Object1_y',\n",
    " '_Object1_width',\n",
    " '_Object1_height',\n",
    " '_Object2_',\n",
    " '_Object2_x',\n",
    " '_Object2_y',\n",
    " '_Object2_width',\n",
    " '_Object2_height',\n",
    " '_Object3_',\n",
    " '_Object3_x',\n",
    " '_Object3_y',\n",
    " '_Object3_width',\n",
    " '_Object3_height',\n",
    " '_Object4_',\n",
    " '_Object4_x',\n",
    " '_Object4_y',\n",
    " '_Object4_width',\n",
    " '_Object4_height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Add your image transformation (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_image_transformation(image_size='640', image_resize_type=\"RETAIN_ASPECTRATIO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Start training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking out for steady decrease in our losses throughout the epochs. As the task is to classify and detect the position of defects, keep a look out for the box loss and class loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(table=train_set.name, \n",
    "            inputs='_image_', \n",
    "            targets=obj_det_targets,\n",
    "            index_variable=['_Object0_', '_Object1_', '_Object2_', '_Object3_', '_Object4_'], \n",
    "            log_level=4, \n",
    "            gpu = [0],\n",
    "            seed=1234, \n",
    "            optimizer=optimizer,\n",
    "            batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Score the Model and Visualize Scoring Results <a id=\"score\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Score the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `modelzoo cas action set` method to score the test data. The score results are written to `tableOut`. The `tableOut` value is a `CASTable` that contains the labels, the annotated image predictions, and the filename column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = DLPyDict(logLevel=log_level_map[4], table=train_set.name, inputs=\"_image_\", targets=obj_det_targets,\n",
    "                              model=model.model_table, batch_size=10,\n",
    "                              indexvariables=model.index_variable, inputIndexmap=model.index_map,\n",
    "                              options=dict(yaml=str(model.documents_score), label=model.label_name + \"_score\"),\n",
    "                              tableOut=dict(name=\"pcb_scored\",replace=True), copyVars=[\"_image_\"])\n",
    "\n",
    "rt = model.conn.retrieve('dlModelZoo.dlmzscore', _messagelevel='note', **parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Visualize scored results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results = s.CASTable(\"pcb_scored\", where=\"_nObjects_ > 0\")\n",
    "score_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Save our model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_to_astore(path='.', \n",
    "                     file_name=\"pcb_yolov5s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Register Model to model repository <a id=\"register\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sasctl import Session, register_model\n",
    "from sasctl.services import model_repository\n",
    "\n",
    "with Session(\"https://gtptest.apdemo.sas.com\", username, password):\n",
    "    register_model(model= s.CASTable(\"MODEL_1P4OXD_ASTORE\"), \n",
    "                   name = 'Yolov5_Original', \n",
    "                   project = 'dc1b7958-c6df-4153-835f-fdba1afbcbcc',\n",
    "                   repository='Public',\n",
    "                   version='latest')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have come to the end of the model development hands-on. As a good practice, please remember to terminate your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
